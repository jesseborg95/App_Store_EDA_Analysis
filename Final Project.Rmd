---
title: "DATS6101 Group Project: App Analysis"
author: "Jonathan Giguere, Jesse Borg, Ese Emuraye, Sarah Gates"
date: "October 23rd 2019"
output:
  html_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(include = TRUE)
```

```{r basicfcn, include=F}
# can add quietly=T option to the require() function
loadPkg = function(x) { if (!require(x,character.only=T, quietly =T)) { install.packages(x,dep=T,repos="http://cran.us.r-project.org"); if(!require(x,character.only=T)) stop("Package not found") } }
```

```{r, packages, include = F}
library(magrittr)
library(corrplot)
library(ggplot2)
library(plyr)
library(dplyr)
library(viridis)
library(viridisLite)
library(corrplot)
library(car)
```

```{r outlierKD_def, include=FALSE}
# modified to allow prompt-free run-through
outlierKD <- function(dt, var, rmv=NULL) { 
     var_name <- eval(substitute(var),eval(dt))
     na1 <- sum(is.na(var_name))
     m1 <- mean(var_name, na.rm = T)
     sd1 <- sd(var_name,na.rm = T)
     par(mfrow=c(2, 2), oma=c(0,0,3,0))
     boxplot(var_name, main="With outliers")
     hist(var_name, main="With outliers", xlab=NA, ylab=NA)
     outlier <- boxplot.stats(var_name)$out
     mo <- mean(outlier)
     var_name <- ifelse(var_name %in% outlier, NA, var_name)
     boxplot(var_name, main="Without outliers")
     hist(var_name, main="Without outliers", xlab=NA, ylab=NA)
     title("Outlier Check", outer=TRUE)
     na2 <- sum(is.na(var_name))
     cat("Outliers identified:", na2 - na1, "n")
     cat("Propotion (%) of outliers:", round((na2 - na1) / sum(!is.na(var_name))*100, 1), "n")
     cat("Mean of the outliers:", round(mo, 2), "n")
     m2 <- mean(var_name, na.rm = T)
     cat("Mean without removing outliers:", round(m1, 2), "n")
     cat("Mean if we remove outliers:", round(m2, 2), "n")
     #
     if(is.null(rmv)) { 
       response <- readline(prompt="Do you want to remove outliers and to replace with NA? [yes/no]: ") 
     } else {
       if (rmv=='y'|rmv=='yes'|rmv=='Y'|rmv=='Yes'|rmv=='YES'|rmv==TRUE ) { response = 'y' } else { response = 'n' }
     }
     #
     if(response == "y" | response == "yes"){
          dt[as.character(substitute(var))] <- invisible(var_name)
          assign(as.character(as.list(match.call())$dt), dt, envir = .GlobalEnv)
          cat("Outliers successfully removed", "n")
          return(invisible(dt))
     } else{
          cat("Nothing changed", "n")
          return(invisible(var_name))
     }
}
```

## Section 1: Introduction

The popularity of smartphones has increased greatly every year since Apple released the Iphone in 2007, with approximately 10 billion [Statista](https://statista.com) smartphones sold worldwide since then. Of these 10 billion; iPhones account for almost 20% of sales with a total revenue of $165 billion in 2018 alone [CEO World Magazine](https://ceoworld.biz). Since the meteoric rise of the smartphone and tech industries, many app developers have taken the opportunity to develop their own apps for different operating systems and made them available to download on the App Store and/or the Google Play Store. Today, there are over 2.2 billion iOS apps [Lifewire](https://lifewire.com) and 2.7 billion apps on the Google Play Store [Statista](https://statista.com). On average, people spend around 3 hours a day on their phones [Hacker Noon](https://hackernoon.com). Due to the huge popularity of apps, there is a wide variety of genres available for every type of audience with a wide range of pricing. Since many people invest so much time and effort into apps, app data has become an interesting and relevant topic to conduct more research on. 

This report focuses mainly on a sample of apps from the Google Play Store, where the composition of this sample will be analysed in depth. The report itself will contain 6 additional chapters: Chapter 2 looks at the source data and the general composition of the dataset. Chapter 3 compares the apps in the App Store to that in the Google Play Store; chapter 4 looks at the different app categories; chapter 5 analyses the pricing of the apps and looks at the relationship between app pricing and popularity. Finally chapter 6 is the report conclusion where we report our findings based on the analysis.

## Section 2: Description of Data

### 2.1 Discussion of Data Sources

The data for our EDA comes from two datasets that our team discovered on [Kaggle](https://www.kaggle.com).  The first dataset contains information about apps in the Google Play Store. The second contains information about apps in the App Store.  First, we will describe the data pertaining to the Google Play Store.

#### Google Play Store Data

The Google Play Store dataset contains records for 10,840 different apps.  The variables, and their descriptions are given below:

* **App** - The name of the application
* **Category** - The category that the app belongs in
* **Rating** - The current app rating on a scale from 1 to 5 (1 being the lowest)
* **Reviews** - The number of reviews for the app
* **Size** - Size of the app given in MB
* **Installs** - Number of installs given as categories (ex. 10,000+)
* **Type** - Tells which apps are free and which require payment
* **Price** - Gives the Price for each app
* **Content_Rating** - Indicates which age groups the app is approved for
* **Last Updated** - Date the app was last updated
* **Current.Ver** - Current Version of the app

```{r import Google Play Data, echo=F}
library("stringr")
# setwd("/Users/jonathangiguere/Desktop/DATS 6101/Projects/Project 1/Data-Science-Project-Final-master")
googlePlay <- read.csv('googleplaystore.csv')
googlePlay <- subset(googlePlay, select = -c(Android.Ver, Genres) )
googlePlay$Size <- str_remove(googlePlay$Size, 'M')
str(googlePlay)
```

#### Apple Store Data

The Apple App Store dataset contains records for 7,197 different apps.  The variables, and their descriptions are given below:

* **App** - The name of the application
* **Category** - The category that the app belongs in
* **Rating** - The current app rating on a scale from 1 to 5 (1 being the lowest)
* **Reviews** - The number of reviews for the app
* **Size** - Size of the app given in MB
* **Price** - Gives the Price for each app
* **Content_Rating** - Indicates which age groups the app is approved for
* **Current_Ver** - Current_Version of the app

```{r import Apple Store Data, echo=F}
appleStore <- read.csv('applestore.csv')
appleStore <- subset(appleStore, select = -c(id, currency, rating_count_ver,
                                             user_rating_ver, sup_devices.num,
                                             ipadSc_urls.num, lang.num,
                                             vpp_lic))
colnames(appleStore) <- c('X', 'App', 'Size', 'Price', 'Reviews',
                          'Rating', 'Current_Ver', 'Content_Rating',
                          'Category')
appleStore$Size <- round(appleStore$Size/1000000, 0)
str(appleStore)
```

### 2.2 Cleaning the Data

#### 2.2.1 Removing Null Values

First, we check how many null values are in the playstore data frame:
```{r check NA, echo = F, include = T}

# review how many fields are NA
plotNA <- barplot(colSums(is.na(googlePlay)),
                  col = "lightblue",
                  main = "Playstore NA Values",
                  ylab = "Count of Null Values",
                  xlab = "App Categories",
                  las = 2)
                  
```


```{r clean NA, echo = F, include = F}
# create new data frame for apps where NA is null, then remove rating NAs from main playstore dataset
ratingNA <- subset(googlePlay, is.na(Rating))
googlePlay = na.omit(googlePlay)

# to double check that the NAs have been removed
sapply(googlePlay,function(x)sum(is.na(x)))
```

The only field with null values is Rating with 1474 missing values. We will store these values in a separate data frame in case we would like to do future analysis on this data. Then we will remove them from the main playstore dataset.

Now we will check whether there are duplicates. We will do this by checking the difference between all and unique object.
```{r check dups, echo = F, include = F}

distinct <- nrow(googlePlay %>%
  distinct(App))

duplicates <- nrow(googlePlay) - distinct
```

There are `r duplicates` duplicates in the data. The next step is to remove duplicates from playstore.

```{r remove dups, echo = F, include = F}

googlePlay = googlePlay[!duplicated(googlePlay$App), ]


# to double check that the duplicates have been removed
distinct <- nrow(googlePlay %>%
  distinct(App))

nrow(googlePlay) - distinct
```

The only field with null values is 'Rating', with 1474 missing values. We will store these values in a separate data frame in case we would like to do future analysis on this data. Then we will remove them from the main playstore dataset.

Next, to clean the data we will change the Installs variable from a nominal categorical variable to an ordinal categorical variable. Installs is a variable buckets the range of the number of times an app has been installed. We will place the factor levels in order from least to greatest.

```{r order installs, echo = F, include = F}

factor(googlePlay$Installs, order = TRUE, 
       levels = c("0", "0+", "1+", "5+", "10+", "50+", "100+", "500+", "1,000+", "5,000+", "10,000+", "50,000+", "100,000+", "500,000+", "1,000,000+", "5,000,000+", "10,000,000+", "50,000,000", "100,000,000+", "500,000,000+", "1,000,000,000+"))

```

## Section 3: Comparison of the App Store and Google Play Store

We will begin our analysis by comparing both the App Store and the Google Play Store datasets.  After comparing both data sources, we will select one to use for further in depth analysis.

The App Store dataset originally contained 7197 different apps whereas the Google Play Store originally contained 10840.  After the cleaning was performed, the Google Play Store has 8196 records for different apps.

### 3.1 SMART Question
#### Are there any variables present in one dataset that do not exist in the other?

Here we can see that the Google Play Store has more variables of interest than the App Store.  The App Store does not have a variable for number of installs, which is something we might want to use in our analysis.

Google Play Store  | App Store   | 
-----|-----|
App |  App | 
Category  | Category |  
Rating  | Rating |  
Reviews |Reviews| 
Size | Size| 
Installs | *N/A* | 
Type |*N/A* | 
Price | Price |
Content.Rating | Content_Rating| 
Last.Updated | *N/A* |  
Current.Ver | Current_Ver |


### 3.2 SMART Question
#### How do users rate apps in each app store?

Rating will most likely be a response variable of interest later in our analysis so we begin our comparison of the two app stores by looking at the distributions of ratings for each.  

```{r rating distributions for each}
hist(googlePlay$Rating, main = 'Frequency of Ratings for the Google Play Store', xlab = 'Rating', col = viridis(20),
     xlim=c(0,5))
hist(appleStore$Rating, main = 'Frequency of Ratings for the App Store', xlab = 'Rating', col = viridis(12),
     xlim=c(0, 5))
```



```{r Rating Mean and SD, echo=F, include=F}
#Get average ratings for both stores
avg_rating_google <- round(mean(googlePlay$Rating), 2)
avg_rating_apple <- round(mean(appleStore$Rating), 2)

#Get standard deviations of ratings for both stores
sd_rating_google <- round(sd(googlePlay$Rating), 2)
sd_rating_apple <- round(sd(appleStore$Rating), 2)

avg_rating_google
avg_rating_apple

sd_rating_google
sd_rating_apple
```

Upon inspection of the frequency distributions for each, we can see that neither is normally distributed and both are left skewed favoring higher rating.  Due to the non-normal distributions, a two-sample t-test cannot be performed to evaluate the relationship between average ratings in each store.  Instead we have simply calculated the mean and standard deviation of each for further comparison.

 Statistic |Google Play Store  | App Store   | 
----|-----|-----|
 Mean|  `r avg_rating_google` | `r avg_rating_apple` |
Standard Deviation| `r sd_rating_google`  | `r sd_rating_apple` |  

We notice that the Google Play Store has a higher average rating for its apps than the App Store.  We also notice that the variation in rating is lower in the Google Play Store.  Some of this phenemenon could be attributed to the fact that the Google Play Store has ratings in increments of 0.1 while the App Store uses increments of 0.5.

### 3.3 SMART Question
#### How many apps are available in both app stores and how do their ratings compare?

```{r # of reviews exploration, echo=F, include=F}
#find common apps in both datasets
a <-intersect(googlePlay$App, appleStore$App)

#subset new dataframes that contain the common apps in each store
googleCommon <- googlePlay[googlePlay$App %in% a, ]

#Remove duplicate app records
googleCommon <- distinct(googleCommon, App, .keep_all = T)

appleCommon <- appleStore[appleStore$App %in% a, ]

#Number of apps in common
length(appleCommon$X)
length(googleCommon$App)
```
After using the intersect() function to compare app names in both stores, there are a total of **`r length(appleCommon$X)`** apps in common.  Now that we have dataframes containing common apps in both stores, we can revisit our ratings histogram to get a better idea of which store rates higher on average.  

```{r ratings histogram-common apps}
#hist(googleCommon$Rating, main = 'Histogram of frequency rating for the Google Playstore', xlab = 'Rating', col = viridis(20),
     #xlim=c(0,5))
#hist(appleCommon$Rating, main = 'Histogram of frequency rating for the Apple Store', xlab = 'Rating', col = viridis(12),
     #xlim=c(0,5))
```

Upon inspection, the histograms (not pictured for brevity) were left skewed and not normally distributed so performing a two-sided t-test would be inappropriate here.  As such, we have calculated the mean and standard deviation of each below and compared it to the mean and standard deviation from above where all apps were considered.

```{r Rating Mean and SD for common, echo=F, include=F}
#Get average ratings for both stores
avg_rating_common_google <- round(mean(googleCommon$Rating), 2)
avg_rating_common_apple <- round(mean(appleCommon$Rating), 2)

#Get standard deviations of ratings for both stores
sd_rating_common_google <- round(sd(googleCommon$Rating), 2)
sd_rating_common_apple <- round(sd(appleCommon$Rating), 2)

avg_rating_common_google
avg_rating_common_apple

```


 Statistic |Google Play Store  | App Store   | 
----|-----|-----|
 Mean (All Apps Inlcuded) |  `r avg_rating_common_google` | `r avg_rating_common_apple` |
 Mean (Common Apps) |  `r avg_rating_google` | `r avg_rating_apple` |
Standard Deviation (All Apps Inlcuded) | `r sd_rating_google`  | `r sd_rating_apple` |
Standard Deviation (Common Apps) | `r sd_rating_common_google`  | `r sd_rating_common_apple` |

Once again, the Google Play Store has higher average ratings and than the App Store and less variation.  This tells us that for the exact same apps present in both stores, they tend to be rated higher in the Google Play Store.

### 3.4 SMART Question
#### Is one store more expensive than the other?

Before selecting one dataset to analyze further, we thought it would be wise to look at price comparisons between the two in case there are differences.  In order to do so, we combined our dataframes consisting of all apps found in both stores.  This allowed us to create a bar chart showing the sum of Price for each store for all shared apps.  

```{r get new dataframe to make price boxplots}
googleCommonBoxplot <- googleCommon
#Add column of 1s to identify google store
googleCommonBoxplot$StoreType <- as.factor(rep(1, nrow(googleCommonBoxplot)))
#Select only columns needed for barchart
googleCommonBoxplot <- select(googleCommonBoxplot, c(App, Price, StoreType))
#Change price from factor to character bc cannot go straight to num
googleCommonBoxplot$Price <- as.character(googleCommonBoxplot$Price)
#Now drop dollar sign and convert to numeric
googleCommonBoxplot$Price <- as.numeric(gsub("\\$", "", googleCommonBoxplot$Price))


appleCommonBoxplot <- appleCommon
#Add column of 0s to identify apple store
appleCommonBoxplot$StoreType <- as.factor(rep(0, nrow(appleCommonBoxplot)))
#Select only columns needed for barchart
appleCommonBoxplot <- select(appleCommonBoxplot, c(App, Price, StoreType))

#Put the dataframes together
price_compare_DF <- rbind(googleCommonBoxplot, appleCommonBoxplot)
```

```{r Make barchart}

ggplot(price_compare_DF, aes(x=StoreType, y=Price, fill = StoreType)) +
  geom_col() +
  coord_flip() +
  labs(y='Price $ USD') +
  ggtitle("Total Cost of Apps for Apps Found in Both Stores") +
  theme(legend.position = 'none', plot.title = element_text(hjust = 0.5), axis.title.y = element_blank()) +
  scale_x_discrete(labels=c("0" = "App Store", "1" = "Google Play Store")) +
  scale_fill_manual("legend", values=c("0"="aquamarine4", "1"="aquamarine3"))
```

```{r pie}
#appleStore$Type <- factor(ifelse(appleStore$Price == 0.00, 0, 1), labels = c('Free', 'Paid'))

#ggplot(appleStore, aes(x = " ", y=Type, fill = Type)) +
  #geom_bar(stat = "identity") +
  #ggtitle('Price Composition of Apps in the Appstore') +
  #coord_polar("y", start=0) +
  #theme_void()

#ggplot(googlePlay, aes(x = " ", y=Type, fill = Type)) +
  #geom_bar(stat = "identity") +
  #ggtitle('Price Composition of Apps in the Google Playstore') +
  #coord_polar("y", start=0) +
  #theme_void()
```


Upon inspection of the chart, we can see that some of the same apps differ in price depending which store they are in.  Based on the apps the original datasets have in common, it would be more expensive to purchase all of them from the App Store.  This could mean that the Apple App Store is more expensive, or at least it is for the apps present in our sample.  


## Section 4: App Categories

### 4.1 SMART Question

Does app category have a correlation with rating, which categories in the Google Play Store have the highest priced apps and which category has the most highly rated apps?

### 4.2 Category Analysis

By grouping apps by category, we can determine the average rating by category and average price, as well as overall number of apps and number of apps  by category. The most common categories are family, game and tools; below the category distrubution of apps is shown.

```{r bar2, echo = F}
ggplot(googlePlay, aes(Category)) + 
        geom_bar(fill = viridis(33), color = 'black') +
        ggtitle('Number of Apps in the Google Playstore by Category') +
        ylab('Number of Apps') +
        coord_cartesian(ylim = c(0,1250)) +
        theme_classic() +
        theme(plot.title = element_text(hjust = 0.5)) + 
        theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 8, color = 'black'))
```

### 4.3 Categories by Rating

To find the highest and lowest rated categories, the ratings were aggregated according to the app category and the mean was then found for each category. Once the means were found, they were then plotted and a conclusion was drawn.

```{r bary, echo = F}
catrating <- aggregate(googlePlay$Rating, list(googlePlay$Category), mean, na.rm = TRUE)
names(catrating) <- c('Category', 'Avg_Rating')

ggplot(catrating, aes(x = reorder(Category, -Avg_Rating), y = Avg_Rating)) +
        geom_bar(stat = 'Identity', fill = viridis(33), color = 'black') +
        ggtitle('Average Rating of Apps in the Google Playstore by Category') +
        ylab('Average Rating') +
        coord_cartesian(ylim = c(3.75, 4.5)) +
        theme_classic() +
        theme(plot.title = element_text(hjust = 0.5)) +
        theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 8, color = 'black'))
```

Highest Average Rating by Category

```{r top rating}
head(catrating[order(catrating$Avg_Rating, decreasing = TRUE),], n = 5)
```


Lowest Average Rating by Category

```{r bottom rating}
tail(catrating[order(catrating$Avg_Rating, decreasing = TRUE),], n = 5)
```

The highest rated categories on average are Events, Education and Art & Desgin, while the lowest rated categories are Maps & Navigation, Tools and Dating.

### 4.4 Categories by Price

To get the average price of each category, a new subset was created which just contained the paid apps. Then, similarly to the previous section, the prices were aggregated according to the category, the means were calculated and then plotted.
``` {r type2, include = F}
free <- subset(googlePlay, googlePlay$Type == 'Free')
paid <- subset(googlePlay, googlePlay$Type == 'Paid')

print(nrow(free))
print(nrow(paid))
```

```{r barx, echo = F}
paid$Cost = as.numeric(gsub("\\$", "", paid$Price))
catprice <- aggregate(paid$Cost, list(paid$Category), mean)
names(catprice) <- c('Category', 'Avg_Price')

ggplot(catprice, aes(x = Category, y = Avg_Price)) +
        geom_bar(stat = 'Identity', fill = viridis(28), color = 'black') + 
        ggtitle('Average Price of Paid Apps in the Google Playstore by Category') +
        ylab('Average Price ($)') +
        coord_cartesian(ylim = c(0,20)) +
        theme_bw() +
        theme(plot.title = element_text(hjust = 0.5)) + 
        theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 7, color = 'black')) +
        theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank())
```

Highes Average Price by Category

```{r top paid}
head(catprice[order(catprice$Avg_Price, decreasing = TRUE),], n = 5)
```

Even though most of the apps in the Google Play Store are free; with `r nrow(free)` free apps and `r nrow(paid)` paid apps. Out of those paid apps, the most expensive ones on average are Finance and Lifestyle apps by a long shot. 

### 4.5 Which app category in the Google Play Store receives most high ratings?

In this section, we would like to identify the most well rated app categories in the Google Play Store. We define ‘most well rated’ as ratings that are greater or equal to 4.8. The score 4.8 is chosen because 95% of app ratings in the Google Play Store are below 4.8. In other words, only 5% of the Google Play Store apps have ratings that are greater or equal to 4.8. Therefore, the 95th percentile helps us to filter the best rated apps.

```{r hist2}
hist(googlePlay$Rating, main = 'Histogram of frequency rating for the Google Play Store', xlab = 'Rating', col = viridis(20))
```

```{r percentile, include = F}
quantile(googlePlay$Rating, .95)
```
According to the 95th percentile, the apps in the top 5% having a rating of 4.8 or higher.

```{r best rated}
top_rated <- subset(googlePlay, googlePlay$Rating >= 4.8)
top_count <- plyr::count(top_rated$Category)
names(top_count) <- c('Category', 'Count')
top_count <- top_count[order(top_count$Count, decreasing = TRUE),]
```

To find the categories containing the most apps with a rating of 4.8 or greater, a new subset was created from the Google Play Store dataframe which only contained apps with a rating of 4.8 or greater. There are `r nrow(top_rated)` apps which fall within the highly rated threshold of 4.8. After this, the number of apps from each catergory within this subset was found using the count function. This count was then plotted into a bar chart to graphically demonstrate the distrubution of highly rated apps within different categories.

```{r topplot}
ggplot(top_count, aes(x = reorder(Category, -Count), y = Count)) +
        geom_bar(stat = 'Identity', fill = plasma(32), color = 'black') + 
        ggtitle('Highly Rated Apps in the Google Play Store by Category') +
        ylab('Total') +
        xlab('Category') +
        coord_cartesian(ylim = c(0,60)) +
        theme_bw() +
        theme(plot.title = element_text(hjust = 0.5)) + 
        theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 7, color = 'black')) +
        theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank())
```

Categories with the most highly rated apps.

```{r topr}
head(top_count[order(top_count$Count, decreasing = TRUE),], n = 5)
```

Catergories with the highest ratings are Family (by a large margin), then Lifestyle, Medical and Health & Fitness being very similar.

Overall; the highest rated apps on average are in the Events category, the most expensive apps are in the Finance category and the category with the most highly rated apps are Family.

## Section 5: App Pricing


### 5.1 SMART QUESTION: How does the price influence the distribution of apps across category, rating and content rating

``` {r type, echo = F}
# Create two new dataframes for free and paid apps separately
freeApps <- subset(googlePlay, googlePlay$Price == 0.00)
paidApps <- subset(googlePlay, googlePlay$Price != 0.00)

```

There are `r nrow(freeApps)` free apps and `r nrow(paidApps)` paid apps corresponding to `r format((nrow(freeApps)/nrow(googlePlay))*100, digits=3)`% and `r format((nrow(paidApps)/nrow(googlePlay))*100, digits=3)`% respectively in Google playstore 


### 5.2 Do users rate free apps better than paid apps across different categories?

For the different categories in Google Playstore, we want to understand the rating behavior of users for free apps as well as paid apps
```{r echo=F}
# Create new dataframe and new column, assign categorical values of 0 and 1 for free and paid apps respectively   
  googlePlay_cat <- googlePlay[which(googlePlay$Price == 0.00 |googlePlay$Price != 0.00), ]
  googlePlay_cat$PriceCat <- factor(ifelse(googlePlay_cat$Price == 0.00, 0, 1), labels = c("Free", "Paid"))
  
  ggplot(googlePlay_cat, aes(x = Category, y = Rating)) +
    geom_boxplot(fill=viridis(61)) +
    #ggtitle("Boxplot of User Rating by Genre across Free Vs Paid Apps")
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + 
    theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6, color = 'black')) +
    facet_grid(. ~ PriceCat)
```

From the boxplot above, we observe that free apps have a well distributed mean rating across categories compared to paid apps

```{r echo = F}
# create new dataframe containing different categories and their respective average rating for free apps
catFreeRating = freeApps %>% group_by(Category) %>% dplyr::summarise( Avg_rating = mean(Rating)) %>% arrange(desc(Avg_rating)) %>% mutate(Category = factor(Category, levels = unique(Category)))

ggplot(catFreeRating, aes(x = Category, y = Avg_rating)) + 
  geom_bar(stat = 'Identity', fill = viridis(33), color = "black") +
  ggtitle("Average Rating of Free Apps by Category") +
  ylab('Average Rating') +
  coord_cartesian(ylim = c(3, 5)) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 9, color = 'black')) +
  theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank())
```


```{r echo = F}
# create new dataframe containing different categories and their respective average rating for paid apps

catPaidRating = paidApps %>% group_by(Category) %>% dplyr::summarise( Avg_rating = mean(Rating)) %>% arrange(desc(Avg_rating)) %>% mutate(Category = factor(Category, levels = unique(Category)))

ggplot(catPaidRating, aes(x = Category, y = Avg_rating)) + 
  geom_bar(stat = 'Identity', fill = viridis(28), color = "black") +
  ggtitle("Average Rating of Paid Apps by Category") +
  ylab('Average Rating') +
  coord_cartesian(ylim = c(3, 5)) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 9, color = 'black')) +
  theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank())

```

# 5.3 Do users rate free apps better than paid apps?
Top 5 rated category in Free Apps 
```{r echo=F}
# top rated categories for free apps 
  top5free <- head(catFreeRating, n = 5)
```

`r top5free`


Top 5 rated category in Paid Apps 
```{r echo=F}
# top rated caetegories for paid apps
  top5paid <- head(catPaidRating, n = 5)
```

`r top5paid`

### 5.4 How do users rate apps across different content rating for free and paid apps

For the different content categories in Google Playstore, we want to understand the rating behavior of users for free apps as well as paid apps

```{r echo=F}
  ggplot(googlePlay_cat, aes(x = Content.Rating, y = Rating)) +
      geom_boxplot(fill=viridis(10)) +
      ggtitle("Boxplot of User Rating by Content Rating across Free Vs Paid Apps")+
      facet_grid(. ~ PriceCat) +
      theme_bw() +
      theme(plot.title = element_text(hjust = 0.5)) +
      theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
      theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6, color = 'black'))      
```


### 5.5 How are free apps distributed by category
```{r d, echo = F}
# create a dataframe sorted by count of category for free apps and plot
freeAppsCount <- freeApps %>% group_by(Category) %>% dplyr::summarise(NumOfApps = n()) %>% arrange(NumOfApps) %>% mutate(Category = factor(Category, levels = unique(Category)))


 ggplot(freeAppsCount, aes(x=Category, y=NumOfApps)) +
  geom_bar( fill = viridis(33), color = 'black', stat = 'identity') +
  ggtitle('Free Apps in the Google Playstore by Category') + 
  xlab('Category') + ylab('Number of Apps') + 
  #coord_cartesian(ylim = c(0, 1800)) + 
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 8, color = 'black')) +
  theme(axis.text.y = element_text(size = 8, color = 'black')) +
  coord_flip()

```

### 5.6 What are the Top 5 Categories for Free Apps

```{r echo=F}
  tail(freeAppsCount)
```

### 5.7 How are paid apps distributed by category

```{r echo = F}
# create a dataframe sorted by count of category for paid apps and plot
paidAppsCount <- paidApps %>% group_by(Category) %>% dplyr::summarise(NumOfApps = n()) %>% arrange(NumOfApps) %>% mutate(Category = factor(Category, levels = unique(Category)))

ggplot(paidAppsCount, aes(x = Category, y = NumOfApps)) +
  geom_bar(fill = viridis(28), color = 'black', stat = 'identity') +
  ggtitle('Paid Apps in Google Playstore by Category') + 
  xlab('Category') + ylab('Number of Apps') + 
  #coord_cartesian(ylim = c(0, 200)) + 
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 8, color = 'black')) +
  theme(axis.text.y = element_text(size = 8, color = 'black')) +
  coord_flip()
```

### 5.8 What are the Top 5 Categories for Paid Apps
```{r echo=F}
  tail(paidAppsCount)
```

 
### 5.10 How are the apps distributed across different price categories

The price of apps is divided into categories, with the price range $0.99 - $9.99, $10 - $99.99 and $100 - $400 corresponding to cheap, expensive and very expensive respectively

```{r echo=F}
# clean price column and split into categories
# strip the dollar sign off the price and convert to numeric data type
  paidApps$Price <- as.numeric(str_remove(paidApps$Price, '\\$'))

# Create new column and a split price into different categories
  paidApps$PriceCategory <- cut(paidApps$Price, breaks = c(0, 10, 100, 401), labels = c("Cheap", "Expensive", "Very Expensive"), right=FALSE)
```

```{r echo=F}
# Plot bar chart showing the number of apps for different price categories
  ggplot(paidApps, aes(PriceCategory)) +
  geom_bar(fill = viridis(3), color = 'black') +
  ggtitle('Paid Apps in Google Playstore by Price Category') + 
  xlab('Price Category') + ylab('Number of Apps') + 
  coord_cartesian(ylim = c(0, 700)) + 
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + 
  theme(axis.text.x = element_text(angle = 0, hjust = 1, size = 8, color = 'black'))
```
 
 From the bar chart above, most of the apps fall under the cheap category

### 5.11 What are the average ratings across different price categories

```{r echo=F}
# create a data frame, group by price category, calulate and sort by average rating
  priceCatRating = paidApps %>% group_by(PriceCategory) %>% summarise( Avg_rating = mean(Rating)) %>% arrange(Avg_rating)

# Plot bar chart showing the average rating for different price categories
ggplot(priceCatRating, aes(x = PriceCategory, y = Avg_rating)) + 
  geom_bar(stat = 'Identity', fill = viridis(3), color = "black") +
  ggtitle("Average Rating of Paid Apps by Price Category") +
   ylab('Average Rating') +
   xlab('Price Category') +
  coord_cartesian(ylim = c(2.5, 5.5)) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(axis.text.x = element_text(angle = 0, hjust = 1, size = 9, color = 'black')) +
  theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank())
```

### 5.12 Are the average ratings the same across different price categories

Null Hypothesis: The average ratings are the same across all price categories

Alternate Hypothesis: The average ratings are the different 
```{r echo=F}
# Create dataframe and store Price Category and User Rating columns and perform anova
    priceCatRating <- subset(paidApps, select = c("PriceCategory", "Rating"))
    anovaRatingPrice <- aov(Rating ~ PriceCategory,  data=priceCatRating)
    summary(anovaRatingPrice)
    anovaRatPrice <- summary(anovaRatingPrice)
    anovaRatPrice[[1]][[5]][[1]]
```

```{r echo=F}
  # perform a tukeyHSD test
  tukeyRatingPrice <- TukeyHSD(anovaRatingPrice)
  tukeyRatingPrice
```

The p-value of `r anovaRatPrice[[1]][[5]][[1]]` is obtained which is lower than our alpha value of 0.05. Hence, we reject the null hypothesis and conclude that there is a significant difference in the average rating across the different price categories. We further under the different in average rating between the price categories using the TukeyHSD test.The result shows a high p-value for the Expensive-Cheap pair, for which we fail to reject the null hypothesis and conclude there is no significant difference in the average ratings for the Expensive-Cheap categories. The Box-plot visualizes this in detail

```{r echo = F}
# Create a boxplot of user rating by different price categories
ggplot(priceCatRating, aes(x = PriceCategory, y = Rating)) +
      geom_boxplot(fill=viridis(3)) +
      ggtitle("Boxplot of User Rating by Price Category")+
      ylab("User Rating") +
      xlab("Price Category") +
      theme_bw() +
      theme(plot.title = element_text(hjust = 0.5)) +
      theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
      theme(axis.text.x = element_text(angle = 0, hjust = 0.5, size = 10, color = 'black'))
```

## 6 Correlation and Linear Models

### 6.1 Plot correlation matrix

We obtain the correlation matrix using the numerical variables
```{r echo=F}
# clean installs column and cast to numeric
  paidApps$Installs <- str_remove(paidApps$Installs, '\\+')
  paidApps$Installs <- as.numeric(gsub(',','',paidApps$Installs))

# create dataframe and store numerical variables
  lcpaidApps <- subset(paidApps, select = c("Rating", "Installs", "Price"))

# Get correlation matrix for all numerical variables
  paidAppsCor = cor(lcpaidApps)
  corrplot(paidAppsCor, method = 'number')

```

### 6.2 Fit different linear models to rating variable

With rating as the target varible, we experiment with different variables to obtain a model that will produce a good fit
```{r include=F}
# fit the price to the rating
  lm1 = lm(Rating ~ Price, data = lcpaidApps)
  summary(lm1)
```

```{r include=F}
# fit the number of app installs to the rating
  lm2 = lm(Rating ~ Installs, data = lcpaidApps)
  summary(lm2)
```

```{r include=F}
# fit the price and number of app installs to the rating
  lm3 = lm(Rating ~ Price+Installs, data = lcpaidApps)
  summary(lm3)
  vif(lm3)
```

Model  |  1 (Price)  |  2 (Installs)  | 3 (Price+Installs) |  
-------|-----|-----|--------|------|  
r^2^  | `r format( summary(lm1)$r.squared )` | `r format( summary(lm2)$r.squared )` | `r format( summary(lm3)$r.squared )`  
Adj r^2^  | `r format( summary(lm1)$adj.r.squared )` | `r format( summary(lm2)$adj.r.squared )` | `r format( summary(lm3)$adj.r.squared )` |  
Price | `r format( lm1$coefficients['Price'] ) ` (vif: 1) | ---------- | `r format( lm3$coefficients['Price'] ) ` (vif: 1.000552) | 
| | p:`r format( summary(lm1)$coefficients[,4]['Price'],digits=3) ` | ----------- | p:`r format( summary(lm3)$coefficients[,4]['Price'],digits=3) ` | 
Installs | | `r format( lm2$coefficients['Installs'] ) ` (vif: 1 ) | `r format( lm3$coefficients['Installs'] ) ` (vif: 1.000552) | 
| | | p:`r format( summary(lm2)$coefficients[,4]['Installs']) ` | p:`r format( summary(lm3)$coefficients[,4]['Installs'])` |  

## Section 6: Popularity Variable

Create a popularity variable by combining rating, reviews, number of downloads?
  - check for normality of rating and number of downloads separately
  - look at correlation between rating and number of downloads
      -need to convert to #
  - standardize each then add together?

Look at revenue

### Section 6.1: SMART Question
FINISH ME ONCE PURPOSE OF VARIABLE DETERMINED


### Section 6.2: Basic Analysis of Rating and Installs

```{r test, echo = F, include = F}

googlePlay <- googlePlay %>%
  mutate(
    InstallsNum = gsub("\\+", "", as.character(Installs)),
    InstallsNum = as.numeric(gsub(",", "", InstallsNum)),
    Rating = as.numeric(Rating),
    Reviews = as.numeric(Reviews)
  )%>%
  filter(
    Type %in% c("Free", "Paid")
  )

extract = c("Rating","Reviews","InstallsNum")
googlePlay.extract = googlePlay[extract]
googlePlay.extract %>% 
  filter(is.nan(googlePlay.extract$Reviews)) %>% 
  filter(is.na(googlePlay.extract$InstallsNum)) %>%
  filter(is.na(googlePlay.extract$Rating))


```


Correlation Plot
```{r corrplot, echo = F, include = T}

googlePlay.extract = na.omit(googlePlay.extract)
cor_matrix = cor(googlePlay.extract)
corrplot(cor_matrix,method = "color",order = "AOE",addCoef.col = "grey")

# mtcarscor = cor(mtcars) # get the CORRELATION MATRIX between all numerical variables.
# mtcarscor
```


Check the normality of the ratings data.
```{r Rating Histogram, echo = F, include = T}

ratingHist <- ggplot(googlePlay, aes(x = Rating)) + 
 geom_histogram(aes(y=..density..), colour="black", fill="white", binwidth = .2)+
 geom_density(alpha=.2, fill="#FF6666") 

ratingHist
```

Check the normality of the number of downloads data. First need to aggregate the buckets so that they are in log scale.

```{r log scale aggregate, echo = F, include = F}

googlePlay <- googlePlay %>%
  mutate(InstallsLog = Installs)

googlePlay$InstallsLog <- gsub("5","1", googlePlay$InstallsLog)

googlePlay$InstallsLog <- factor(googlePlay$InstallsLog, order = TRUE, 
       levels = c("0", "0+", "1+", "10+", "100+", "1,000+", "10,000+", "100,000+", "1,000,000+", "10,000,000+", "100,000,000+", "1,000,000,000+"))

```

NORMALITY ON A LOG SCALE?

```{r Installs Histogram, echo = F, include = T}

googlePlay %>% 
  group_by(InstallsLog) %>% 
  summarise(count = n()) %>%
  suppressWarnings()


installsHist <- ggplot(subset(googlePlay, !is.na(InstallsLog)), aes(x = InstallsLog)) + 
 geom_bar(aes(y= ..count..), colour="black", fill="#AFEEEE", na.rm = TRUE)+
 geom_density(alpha=.2, fill="#AFEEEE") +
 theme(axis.text.x = element_text(angle = 50, hjust = 1))

suppressWarnings(installsHist)
```


```{r standardize data, echo = F, include = F}

standardize <- googlePlay %>%
                  mutate(Installs = scale(InstallsNum)) %>%
                  mutate(Rating = scale(Rating))

head(standardize)
```


```{r scatterplot standardize, echo = F,include = T}

scatterStandardize <- ggplot(standardize, aes(x = Rating, y = Installs)) +
                          geom_point()

scatterStandardize
```